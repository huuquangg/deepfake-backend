{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r /home/huuquangdang/huu.quang.dang/thesis/deepfake/deepfake_backend/libs/model/CelebV2/requirements.txt\n",
    "\n",
    "# # Step 1: Uninstall incompatible NumPy version\n",
    "# %pip uninstall numpy -y\n",
    "# # Step 2: Install compatible NumPy version (< 2.0.0)\n",
    "# %pip install \"numpy>=1.21.0,<2.0.0\"\n",
    "# # Step 3: Verify NumPy version\n",
    "# import numpy as np\n",
    "# print(f\"âœ… NumPy version: {np.__version__}\")\n",
    "# print(f\"Expected: < 2.0.0 (you should see 1.x.x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fd0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T09:44:38.582738Z",
     "start_time": "2025-08-13T09:44:38.568745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, TimeDistributed, GlobalAveragePooling2D, LSTM, Dense, Dropout\n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecf6429cdc7d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:06:51.462172Z",
     "start_time": "2025-06-16T15:06:51.281795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "base_path = '/home/huuquangdang/huu.quang.dang/thesis/Dataset/celeb_df_crop'\n",
    "categories = ['fake', 'real']\n",
    "\n",
    "# Initialize a list to hold data\n",
    "data = []\n",
    "\n",
    "# Process each category\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    for filename in os.listdir(category_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            try:\n",
    "                id_part, frame_part = filename.split('_frame_')\n",
    "                id_ = id_part.split('_')[0]\n",
    "                frame = frame_part.split('.')[0]\n",
    "                data.append({\n",
    "                    'filename': filename,\n",
    "                    'path': os.path.join(category_path, filename),\n",
    "                    'id': int(id_),\n",
    "                    'frame': int(frame),\n",
    "                    'label': category\n",
    "                })\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17e5b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:06:53.591689Z",
     "start_time": "2025-06-16T15:06:53.575495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Äáº£m báº£o Ä‘Ã£ cÃ³ df_cropped.csv chá»©a Ä‘Æ°á»ng dáº«n áº£nh Ä‘Ã£ crop\n",
    "df['label_id'] = df['label'].map({'fake': 0, 'real': 1})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e6874-6fe8-4dff-9f0d-5c7d94337ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:06:56.671685Z",
     "start_time": "2025-06-16T15:06:55.874053Z"
    }
   },
   "outputs": [],
   "source": [
    "df['video_key'] = df['id'].astype(str) + \"_\" + df['label']\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "video_dict = defaultdict(list)\n",
    "labels = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    key = row['video_key']\n",
    "    video_dict[key].append(row['path'])\n",
    "    labels[key] = row['label_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8891d0-4a1f-4bcd-97f2-0b9577706cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:50:19.887250Z",
     "start_time": "2025-06-16T06:50:19.279020Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b99374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from tfkan.layers import Conv2DKAN, DenseKAN  # Import KAN layers\n",
    "from scipy.stats import mode\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "# Giáº£ Ä‘á»‹nh Ä‘Ã£ cÃ³\n",
    "video_keys = list(video_dict.keys())\n",
    "video_labels = [labels[k] for k in video_keys]\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "n_splits = 5\n",
    "sequence_len = 10\n",
    "results = []\n",
    "all_histories = []\n",
    "\n",
    "# Data generator\n",
    "class VideoSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, video_keys, video_dict, labels, batch_size, img_size, sequence_len=10, augment=False):\n",
    "        self.video_keys = video_keys\n",
    "        self.video_dict = video_dict\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.sequence_len = sequence_len\n",
    "        self.augment = augment\n",
    "        self.datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=15 if augment else 0,\n",
    "            zoom_range=0.1 if augment else 0,\n",
    "            horizontal_flip=augment\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.video_keys) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_keys = self.video_keys[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_X, batch_y = [], []\n",
    "\n",
    "        for key in batch_keys:\n",
    "            frames = self.video_dict[key][:self.sequence_len]\n",
    "            imgs = []\n",
    "            for path in frames:\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.resize(img, self.img_size)\n",
    "                img = self.datagen.random_transform(img) if self.augment else img\n",
    "                img = img.astype('float32') / 255.0\n",
    "                imgs.append(img)\n",
    "            while len(imgs) < self.sequence_len:\n",
    "                imgs.append(np.zeros((*self.img_size, 3), dtype='float32'))\n",
    "            batch_X.append(imgs)\n",
    "            batch_y.append(self.labels[key])\n",
    "\n",
    "        return np.array(batch_X), np.array(batch_y)\n",
    "\n",
    "# Build model cáº£i tiáº¿n\n",
    "def build_model(sequence_len, img_size):\n",
    "    base_cnn = MobileNetV2(input_shape=(*img_size, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "    # Freeze toÃ n bá»™ backbone Ä‘á»ƒ giáº£m overfit\n",
    "    base_cnn.trainable = False\n",
    "\n",
    "    # CNN feature extractor\n",
    "    cnn_out = GlobalAveragePooling2D()(base_cnn.output)\n",
    "    cnn_model = Model(inputs=base_cnn.input, outputs=cnn_out)\n",
    "\n",
    "    # Sequence input\n",
    "    input_seq = Input(shape=(sequence_len, *img_size, 3))\n",
    "    x = TimeDistributed(cnn_model)(input_seq)\n",
    "\n",
    "    # Temporal modeling\n",
    "    x = LSTM(64, return_sequences=False)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Classification\n",
    "    x = DenseKAN(1)(x)\n",
    "    output = tf.keras.activations.sigmoid(x)\n",
    "\n",
    "    model = Model(inputs=input_seq, outputs=output)\n",
    "    return model\n",
    "\n",
    "# HMM cáº£i tiáº¿n\n",
    "def hmm_postprocess(pred_probs, y_true, n_states=2):\n",
    "    pred_probs = pred_probs.reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=100)\n",
    "    hmm.fit(pred_probs)\n",
    "    hidden_states = hmm.predict(pred_probs)\n",
    "\n",
    "    mapping = {}\n",
    "    for state in np.unique(hidden_states):\n",
    "        indices = [i for i in range(len(hidden_states)) if hidden_states[i] == state]\n",
    "        state_labels = [y_true[i] for i in indices]\n",
    "        if len(state_labels) > 0:\n",
    "            mapped_label = mode(state_labels, keepdims=True).mode[0]\n",
    "        else:\n",
    "            mapped_label = 0  # fallback\n",
    "        mapping[state] = mapped_label\n",
    "\n",
    "    hmm_labels = np.array([mapping[s] for s in hidden_states])\n",
    "    return hmm_labels\n",
    "\n",
    "# Training K-Fold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (trainval_idx, test_idx) in enumerate(skf.split(video_keys, video_labels), 1):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "\n",
    "    trainval_keys = [video_keys[i] for i in trainval_idx]\n",
    "    test_keys = [video_keys[i] for i in test_idx]\n",
    "\n",
    "    y_trainval = [labels[k] for k in trainval_keys]\n",
    "    train_keys, val_keys = train_test_split(trainval_keys, test_size=0.1, stratify=y_trainval, random_state=fold)\n",
    "\n",
    "    train_gen = VideoSequence(train_keys, video_dict, labels, batch_size, img_size, sequence_len, augment=True)\n",
    "    val_gen = VideoSequence(val_keys, video_dict, labels, batch_size, img_size, sequence_len, augment=False)\n",
    "    test_gen = VideoSequence(test_keys, video_dict, labels, batch_size, img_size, sequence_len, augment=False)\n",
    "\n",
    "    model = build_model(sequence_len, img_size)\n",
    "    model.compile(optimizer=Adamax(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model_path = f\"best_model_fold{fold}.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=epochs,\n",
    "                        callbacks=[checkpoint, earlystop, reduce_lr], verbose=1)\n",
    "    all_histories.append(history.history)\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    y_true = [labels[k] for k in test_keys]\n",
    "    y_pred_prob = model.predict(test_gen).ravel()\n",
    "    y_hmm_pred = hmm_postprocess(y_pred_prob, y_true)\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'accuracy': accuracy_score(y_true, y_hmm_pred),\n",
    "        'precision': precision_score(y_true, y_hmm_pred),\n",
    "        'recall': recall_score(y_true, y_hmm_pred),\n",
    "        'f1': f1_score(y_true, y_hmm_pred),\n",
    "        'auc': roc_auc_score(y_true, y_pred_prob)\n",
    "    })\n",
    "\n",
    "print(\"\\nðŸ“Š Tá»•ng káº¿t káº¿t quáº£ cÃ¡c fold:\")\n",
    "for r in results:\n",
    "    print(f\"Fold {r['fold']}: Accuracy={r['accuracy']:.4f}, F1={r['f1']:.4f}, AUC={r['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96c251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T20:36:15.411930Z",
     "start_time": "2025-06-16T16:43:06.606942Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from tfkan.layers import Conv2DKAN, DenseKAN  # Import KAN layers\n",
    "from scipy.stats import mode\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "# Giáº£ Ä‘á»‹nh Ä‘Ã£ cÃ³\n",
    "video_keys = list(video_dict.keys())\n",
    "video_labels = [labels[k] for k in video_keys]\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "n_splits = 5\n",
    "sequence_len = 10\n",
    "results = []\n",
    "all_histories = []\n",
    "\n",
    "# Data generator\n",
    "class VideoSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, video_keys, video_dict, labels, batch_size, img_size, sequence_len=10, augment=False):\n",
    "        self.video_keys = video_keys\n",
    "        self.video_dict = video_dict\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.sequence_len = sequence_len\n",
    "        self.augment = augment\n",
    "        self.datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=15 if augment else 0,\n",
    "            zoom_range=0.1 if augment else 0,\n",
    "            horizontal_flip=augment\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.video_keys) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_keys = self.video_keys[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_X, batch_y = [], []\n",
    "\n",
    "        for key in batch_keys:\n",
    "            frames = self.video_dict[key][:self.sequence_len]\n",
    "            imgs = []\n",
    "            for path in frames:\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.resize(img, self.img_size)\n",
    "                img = self.datagen.random_transform(img) if self.augment else img\n",
    "                img = img.astype('float32') / 255.0\n",
    "                imgs.append(img)\n",
    "            while len(imgs) < self.sequence_len:\n",
    "                imgs.append(np.zeros((*self.img_size, 3), dtype='float32'))\n",
    "            batch_X.append(imgs)\n",
    "            batch_y.append(self.labels[key])\n",
    "\n",
    "        return np.array(batch_X), np.array(batch_y)\n",
    "\n",
    "# Build model cáº£i tiáº¿n\n",
    "def build_model(sequence_len, img_size):\n",
    "    base_cnn = MobileNetV2(input_shape=(*img_size, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "    # Freeze toÃ n bá»™ backbone Ä‘á»ƒ giáº£m overfit\n",
    "    base_cnn.trainable = False\n",
    "\n",
    "    # CNN feature extractor\n",
    "    cnn_out = GlobalAveragePooling2D()(base_cnn.output)\n",
    "    cnn_model = Model(inputs=base_cnn.input, outputs=cnn_out)\n",
    "\n",
    "    # Sequence input\n",
    "    input_seq = Input(shape=(sequence_len, *img_size, 3))\n",
    "    x = TimeDistributed(cnn_model)(input_seq)\n",
    "\n",
    "    # Temporal modeling\n",
    "    x = LSTM(64, return_sequences=False)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Classification\n",
    "    x = DenseKAN(1)(x)\n",
    "    output = tf.keras.activations.sigmoid(x)\n",
    "\n",
    "    model = Model(inputs=input_seq, outputs=output)\n",
    "    return model\n",
    "\n",
    "# HMM cáº£i tiáº¿n\n",
    "def hmm_postprocess(pred_probs, y_true, n_states=2):\n",
    "    pred_probs = pred_probs.reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=100)\n",
    "    hmm.fit(pred_probs)\n",
    "    hidden_states = hmm.predict(pred_probs)\n",
    "\n",
    "    mapping = {}\n",
    "    for state in np.unique(hidden_states):\n",
    "        indices = [i for i in range(len(hidden_states)) if hidden_states[i] == state]\n",
    "        state_labels = [y_true[i] for i in indices]\n",
    "        if len(state_labels) > 0:\n",
    "            mapped_label = mode(state_labels, keepdims=True).mode[0]\n",
    "        else:\n",
    "            mapped_label = 0  # fallbac\n",
    "            # k\n",
    "        mapping[state] = mapped_label\n",
    "\n",
    "    hmm_labels = np.array([mapping[s] for s in hidden_states])\n",
    "    return hmm_labels\n",
    "\n",
    "# Training K-Fold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (trainval_idx, test_idx) in enumerate(skf.split(video_keys, video_labels), 1):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "\n",
    "    trainval_keys = [video_keys[i] for i in trainval_idx]\n",
    "    test_keys = [video_keys[i] for i in test_idx]\n",
    "\n",
    "    y_trainval = [labels[k] for k in trainval_keys]\n",
    "    train_keys, val_keys = train_test_split(trainval_keys, test_size=0.1, stratify=y_trainval, random_state=fold)\n",
    "\n",
    "    train_gen = VideoSequence(train_keys, video_dict, labels, batch_size, img_size, sequence_len, augment=True)\n",
    "    val_gen = VideoSequence(val_keys, video_dict, labels, batch_size, img_size, sequence_len, augment=False)\n",
    "    test_gen = VideoSequence(test_keys, video_dict, labels, batch_size, img_size, sequence_len, augment=False)\n",
    "\n",
    "    model = build_model(sequence_len, img_size)\n",
    "    model.compile(optimizer=Adamax(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model_path = f\"best_model_fold{fold}.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=epochs,\n",
    "                        callbacks=[checkpoint, earlystop, reduce_lr], verbose=1)\n",
    "    all_histories.append(history.history)\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    y_true = [labels[k] for k in test_keys]\n",
    "    y_pred_prob = model.predict(test_gen).ravel()\n",
    "    y_hmm_pred = hmm_postprocess(y_pred_prob, y_true)\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'accuracy': accuracy_score(y_true, y_hmm_pred),\n",
    "        'precision': precision_score(y_true, y_hmm_pred),\n",
    "        'recall': recall_score(y_true, y_hmm_pred),\n",
    "        'f1': f1_score(y_true, y_hmm_pred),\n",
    "        'auc': roc_auc_score(y_true, y_pred_prob)\n",
    "    })\n",
    "\n",
    "print(\"\\nðŸ“Š Tá»•ng káº¿t káº¿t quáº£ cÃ¡c fold:\")\n",
    "for r in results:\n",
    "    print(f\"Fold {r['fold']}: Accuracy={r['accuracy']:.4f}, F1={r['f1']:.4f}, AUC={r['auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfa766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T01:45:10.343234Z",
     "start_time": "2025-06-17T01:45:10.278158Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"ðŸ“Š Káº¿t quáº£ trung bÃ¬nh:\")\n",
    "print(results_df.mean(numeric_only=True))\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48802125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T07:31:56.035350Z",
     "start_time": "2025-06-14T07:31:50.121545Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, hist in enumerate(all_histories, 1):\n",
    "    plt.figure()\n",
    "    plt.plot(hist['accuracy'], label='Train Acc')\n",
    "    plt.plot(hist['val_accuracy'], label='Val Acc')\n",
    "    plt.title(f'Fold {i} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(hist['loss'], label='Train Loss')\n",
    "    plt.plot(hist['val_loss'], label='Val Loss')\n",
    "    plt.title(f'Fold {i} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc4c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T07:32:05.949380Z",
     "start_time": "2025-06-14T07:32:05.516519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save mÃ´ hÃ¬nh fold cuá»‘i cÃ¹ng\n",
    "model.save(\"mobilenetv2_hmm_faceplus_final.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581629f-92c8-4d93-88f5-8c57f3197a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"ðŸ“Š Káº¿t quáº£ trung bÃ¬nh:\")\n",
    "print(results_df.mean(numeric_only=True))\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167c3f6-2212-4cde-ab07-1ae1449219bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giáº£ sá»­ results Ä‘Ã£ cÃ³ vÃ  báº¡n Ä‘Ã£ táº¡o results_df\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# TÃ­nh cÃ¡c chá»‰ sá»‘\n",
    "accuracy_mean = results_df['accuracy'].mean()\n",
    "accuracy_std = results_df['accuracy'].std()  # dÃ¹ng sample std (chia cho n-1)\n",
    "accuracy_range = results_df['accuracy'].max() - results_df['accuracy'].min()\n",
    "accuracy_cv_percent = (accuracy_std / accuracy_mean) * 100\n",
    "\n",
    "# In káº¿t quáº£\n",
    "print(\"ðŸ“Š Káº¿t quáº£ trung bÃ¬nh:\")\n",
    "print(results_df.mean(numeric_only=True))\n",
    "\n",
    "print(f\"\\nâœ… CV Accuracy (Mean Accuracy): {accuracy_mean:.4f}\")\n",
    "print(f\"ðŸ“ˆ Range Accuracy: {accuracy_range:.4f}\")\n",
    "print(f\"ðŸ“‰ Accuracy CV% (std/mean): {accuracy_cv_percent:.2f}%\")\n",
    "\n",
    "# Hiá»ƒn thá»‹ báº£ng káº¿t quáº£ náº¿u cáº§n\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4efdd-8ae0-4309-9f39-3a151116abb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
